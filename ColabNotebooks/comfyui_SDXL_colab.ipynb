{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaverkaj/Colab/blob/main/ColabNotebooks/comfyui_SDXL_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "# Tutorial Video : https://youtu.be/FnMHbhvWUhE\n",
        "## How To Use Stable Diffusion SD-XL on Colab Full Tutorial / Guide Notebook\n",
        "### [Support me on Patreon please](https://www.patreon.com/SECourses)\n",
        "### [Patreon Exclusive Resources Index](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Patreon-Posts-Index.md)\n",
        "### SECourses YouTube : https://www.youtube.com/SECourses\n",
        "### Now will auto download SDXL 1.0 base and SDXL 1.0 refiner models for you\n",
        "### ComfyUI [GitHub file](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Use-ComfyUI-On-Your-PC-On-RunPod-On-Colab-With-SDXL.md) to download workflows for SDXL :\n",
        "\n",
        "### After selecting previous workflows make sure to change selected model to SDXL 1.0\n",
        "ignore warnings and errors. if not works message me. last tested 26 July 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "outputId": "90c54b42-4b7d-4b3d-917e-e69cb250378d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-= Initial setup ComfyUI =-\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 15803, done.\u001b[K\n",
            "remote: Counting objects: 100% (3716/3716), done.\u001b[K\n",
            "remote: Compressing objects: 100% (424/424), done.\u001b[K\n",
            "remote: Total 15803 (delta 3497), reused 3298 (delta 3292), pack-reused 12087 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15803/15803), 37.80 MiB | 7.00 MiB/s, done.\n",
            "Resolving deltas: 100% (10637/10637), done.\n",
            "/content/ComfyUI\n",
            "-= Updating ComfyUI =-\n",
            "Already up to date.\n",
            "-= Install dependencies =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Collecting xformers!=0.0.18\n",
            "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Collecting torchsde (from -r requirements.txt (line 2))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.47.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.4.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (11.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (5.9.5)\n",
            "Collecting kornia>=0.7.1 (from -r requirements.txt (line 18))\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting spandrel (from -r requirements.txt (line 19))\n",
            "  Downloading spandrel-0.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers!=0.0.18) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (1.18.3)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia>=0.7.1->-r requirements.txt (line 18))\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements.txt (line 20)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 20)) (2.22)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.12.14)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spandrel-0.4.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, kornia-rs, xformers, torchsde, kornia, spandrel\n",
            "Successfully installed kornia-0.7.4 kornia-rs-0.1.7 spandrel-0.4.0 torchsde-0.2.6 trampoline-0.1.2 xformers-0.0.28.post3\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = False  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dddddddddd",
        "outputId": "a0753c4d-6bfd-4333-fb00-cd72100c9952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-25 15:14:28--  https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.45.10, 13.33.45.37, 13.33.45.84, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.45.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/7f/2f/7f2fe2e27137549cd28e570e5bac269b49ebcf1e0e47279c7a941ebe5c948e02/31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sd_xl_base_1.0.safetensors%3B+filename%3D%22sd_xl_base_1.0.safetensors%22%3B&Expires=1735398869&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTM5ODg2OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83Zi8yZi83ZjJmZTJlMjcxMzc1NDljZDI4ZTU3MGU1YmFjMjY5YjQ5ZWJjZjFlMGU0NzI3OWM3YTk0MWViZTVjOTQ4ZTAyLzMxZTM1YzgwZmM0ODI5ZDE0ZjkwMTUzZjRjNzRjZDU5YzkwYjc3OWY2YWZlMDVhNzRjZDYxMjBiODkzZjdlNWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=h6fQE13wSVlZVU-kPv2T93WVMcrxfAanC3ybVHstcbWd-Rzumep3F8VSGB-PrnQ8CU-C7lewIt4-RP14N5vJkqfjOIqFbL33H5sffJ07aYovt%7Etg1HYPXDhABHlXM1--SHG4yMUuxH5j-dsg%7EhTdm3iCDvx0Uz%7E6Wlkr-Iw3lgLnfOeM13oI4fmUAY7mOToFrR73EeGoP2IU%7EOF-U2MtSJ1MGD6-u90vUPmOdilB9Pl%7Eb44sWsmWhHuBLOdQCOo62DkVMffK2E87exqiWa2r-%7EQVHxigjWzGLnqHg2Qopo6UyFb5-Y0742KeuiVubjYm3UbgltAcppkLf531TKHtFQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-25 15:14:29--  https://cdn-lfs.hf.co/repos/7f/2f/7f2fe2e27137549cd28e570e5bac269b49ebcf1e0e47279c7a941ebe5c948e02/31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sd_xl_base_1.0.safetensors%3B+filename%3D%22sd_xl_base_1.0.safetensors%22%3B&Expires=1735398869&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTM5ODg2OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83Zi8yZi83ZjJmZTJlMjcxMzc1NDljZDI4ZTU3MGU1YmFjMjY5YjQ5ZWJjZjFlMGU0NzI3OWM3YTk0MWViZTVjOTQ4ZTAyLzMxZTM1YzgwZmM0ODI5ZDE0ZjkwMTUzZjRjNzRjZDU5YzkwYjc3OWY2YWZlMDVhNzRjZDYxMjBiODkzZjdlNWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=h6fQE13wSVlZVU-kPv2T93WVMcrxfAanC3ybVHstcbWd-Rzumep3F8VSGB-PrnQ8CU-C7lewIt4-RP14N5vJkqfjOIqFbL33H5sffJ07aYovt%7Etg1HYPXDhABHlXM1--SHG4yMUuxH5j-dsg%7EhTdm3iCDvx0Uz%7E6Wlkr-Iw3lgLnfOeM13oI4fmUAY7mOToFrR73EeGoP2IU%7EOF-U2MtSJ1MGD6-u90vUPmOdilB9Pl%7Eb44sWsmWhHuBLOdQCOo62DkVMffK2E87exqiWa2r-%7EQVHxigjWzGLnqHg2Qopo6UyFb5-Y0742KeuiVubjYm3UbgltAcppkLf531TKHtFQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.68.85, 18.155.68.37, 18.155.68.87, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.68.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6938078334 (6.5G) [binary/octet-stream]\n",
            "Saving to: ‘./models/checkpoints/sd_xl_base_1.0.safetensors’\n",
            "\n",
            "sd_xl_base_1.0.safe 100%[===================>]   6.46G   193MB/s    in 56s     \n",
            "\n",
            "2024-12-25 15:15:25 (118 MB/s) - ‘./models/checkpoints/sd_xl_base_1.0.safetensors’ saved [6938078334/6938078334]\n",
            "\n",
            "--2024-12-25 15:15:25--  https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.45.84, 13.33.45.68, 13.33.45.10, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.45.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1735398925&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTM5ODkyNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Z8IhkGKVjgTmCaQNyv5Jg74xD0UvXygohdR3NmsxAEwLrBOs1YtAdbKcLUJpgQ-3XLBx2shZmn99Unr8oc2SsTN7DLlXblcM0D1soaU18uUBgGnJSuElD%7Eakw1BjbxCayJndVsV9gF%7E7iS4vIRum4xKWF7caCCIONxHvsWnjf%7EhL4PaqyjwAMSNOoa8fEvGEldbjojZG0%7EEsUc90vBk0ClhoMx%7EKN0y4DxXHbmfbuZzgYFuW8KedDWvuNiy1UbIa-yH2w2U5BPP2LTctOUsGSTEMB%7EbtFe5wAABQxVYjMnW1BsWphyVJJFAt2I51hiFHmxjfGz86hK6yjZ-%7EU2RN2g__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-25 15:15:26--  https://cdn-lfs.hf.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1735398925&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTM5ODkyNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Z8IhkGKVjgTmCaQNyv5Jg74xD0UvXygohdR3NmsxAEwLrBOs1YtAdbKcLUJpgQ-3XLBx2shZmn99Unr8oc2SsTN7DLlXblcM0D1soaU18uUBgGnJSuElD%7Eakw1BjbxCayJndVsV9gF%7E7iS4vIRum4xKWF7caCCIONxHvsWnjf%7EhL4PaqyjwAMSNOoa8fEvGEldbjojZG0%7EEsUc90vBk0ClhoMx%7EKN0y4DxXHbmfbuZzgYFuW8KedDWvuNiy1UbIa-yH2w2U5BPP2LTctOUsGSTEMB%7EbtFe5wAABQxVYjMnW1BsWphyVJJFAt2I51hiFHmxjfGz86hK6yjZ-%7EU2RN2g__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.68.34, 18.155.68.37, 18.155.68.87, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.68.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 334641190 (319M) [binary/octet-stream]\n",
            "Saving to: ‘./models/vae/vae-ft-mse-840000-ema-pruned.safetensors’\n",
            "\n",
            "vae-ft-mse-840000-e 100%[===================>] 319.14M   203MB/s    in 1.6s    \n",
            "\n",
            "2024-12-25 15:15:27 (203 MB/s) - ‘./models/vae/vae-ft-mse-840000-ema-pruned.safetensors’ saved [334641190/334641190]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checkpoints\n",
        "\n",
        "# SD1.5\n",
        "#!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "!wget -c https://civitai.com/api/download/models/160240 -O ./models/loras/nsfw.safetensors\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "outputId": "3278997b-3d1d-41e6-8d3a-95cb3510d775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0KTotal VRAM 15102 MB, total RAM 12979 MB\n",
            "pytorch version: 2.5.1+cu121\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.5.1+cu118 with CUDA 1108 (you have 2.5.1+cu121)\n",
            "    Python  3.10.15 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "xformers version: 0.0.28.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "****** User settings have been changed to be stored on the server instead of browser storage. ******\n",
            "****** For multi-user setups add the --multi-user CLI argument to enable multiple user profiles. ******\n",
            "[Prompt Server] web root: /content/ComfyUI/web\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://127.0.0.1:8188\n",
            "\n",
            "ComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\n",
            "\n",
            "The password/enpoint ip for localtunnel is: 34.87.135.31\n",
            "your url is: https://brave-moments-follow.loca.lt\n",
            "got prompt\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type EPS\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "CLIP model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "100% 20/20 [00:05<00:00,  3.72it/s]\n",
            "Requested to load AutoencoderKL\n",
            "loaded completely 9.5367431640625e+25 319.11416244506836 True\n",
            "Prompt executed in 46.22 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "100% 20/20 [00:15<00:00,  1.32it/s]\n",
            "Prompt executed in 27.33 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "100% 20/20 [00:15<00:00,  1.29it/s]\n",
            "Prompt executed in 22.55 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "100% 20/20 [00:15<00:00,  1.26it/s]\n",
            "Prompt executed in 22.56 seconds\n",
            "got prompt\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "  0% 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchsde/_brownian/brownian_interval.py:608: UserWarning: Should have tb<=t1 but got tb=14.614643096923828 and t1=14.614643.\n",
            "  warnings.warn(f\"Should have {tb_name}<=t1 but got {tb_name}={tb} and t1={self._end}.\")\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 20.12 seconds\n",
            "got prompt\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.17 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 26.43 seconds\n",
            "got prompt\n",
            "100% 20/20 [00:16<00:00,  1.18it/s]\n",
            "Prompt executed in 19.37 seconds\n",
            "got prompt\n",
            "  0% 0/20 [00:00<?, ?it/s]got prompt\n",
            "  5% 1/20 [00:00<00:15,  1.22it/s]got prompt\n",
            " 10% 2/20 [00:01<00:15,  1.20it/s]got prompt\n",
            " 15% 3/20 [00:02<00:14,  1.20it/s]got prompt\n",
            " 25% 5/20 [00:04<00:12,  1.20it/s]got prompt\n",
            " 30% 6/20 [00:05<00:11,  1.20it/s]got prompt\n",
            " 35% 7/20 [00:05<00:10,  1.20it/s]got prompt\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.22 seconds\n",
            "100% 20/20 [00:16<00:00,  1.18it/s]\n",
            "Prompt executed in 19.30 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.04 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.01 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.10 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.25 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.06 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.00 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Error while deserializing header: MetadataIncompleteBuffer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 328, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 203, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "  File \"/content/ComfyUI/execution.py\", line 174, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 163, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "  File \"/content/ComfyUI/nodes.py\", line 665, in load_lora\n",
            "    lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n",
            "  File \"/content/ComfyUI/comfy/utils.py\", line 36, in load_torch_file\n",
            "    sd = safetensors.torch.load_file(ckpt, device=device.type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 313, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n",
            "\n",
            "Prompt executed in 0.01 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "Requested to load SDXL\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely 9.5367431640625e+25 4897.0483474731445 True\n",
            "  0% 0/20 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "100% 20/20 [00:17<00:00,  1.17it/s]\n",
            "Prompt executed in 24.48 seconds\n",
            "100% 20/20 [00:17<00:00,  1.17it/s]\n",
            "Prompt executed in 19.51 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.01 seconds\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "Prompt executed in 18.84 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.15 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.21 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.23 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.04 seconds\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "  0% 0/20 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  5% 1/20 [00:00<00:14,  1.28it/s]got prompt\n",
            "got prompt\n",
            " 10% 2/20 [00:01<00:14,  1.23it/s]got prompt\n",
            "got prompt\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.66 seconds\n",
            "100% 20/20 [00:17<00:00,  1.16it/s]\n",
            "Prompt executed in 19.61 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.27 seconds\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "Prompt executed in 18.88 seconds\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "Prompt executed in 19.01 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.21 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.20 seconds\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "Prompt executed in 19.08 seconds\n",
            "got prompt\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "  0% 0/20 [00:00<?, ?it/s]got prompt\n",
            "  5% 1/20 [00:00<00:14,  1.27it/s]got prompt\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "Prompt executed in 19.67 seconds\n",
            "100% 20/20 [00:17<00:00,  1.16it/s]\n",
            "Prompt executed in 19.60 seconds\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 19.15 seconds\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
            "  5% 1/20 [00:00<00:14,  1.28it/s]got prompt\n",
            " 10% 2/20 [00:01<00:14,  1.24it/s]got prompt\n",
            "got prompt\n",
            " 15% 3/20 [00:02<00:13,  1.23it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "Prompt executed in 19.52 seconds\n",
            " 65% 13/20 [00:11<00:06,  1.16it/s]"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}